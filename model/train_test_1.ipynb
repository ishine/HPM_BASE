{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지 처리\n",
    "1. TextGrid를 연다 \n",
    "2. interval을 가져온다 \n",
    "3. xmin/xmax를 가져온다 \n",
    "4. frame_rate에 따라 start_frame, end_frame을 구한다. \n",
    "\n",
    "### face: mouth_embedding \n",
    "### VAfeature_256\n",
    "### emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/HPM/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA_VISIBLE_DEVICES: 7\n",
      "CUDA Available: True\n",
      "Device Count: 1\n",
      "Current CUDA Device: 0\n",
      "Using device: cuda:0\n",
      "1.9.0+cu111 1 NVIDIA A100-SXM4-40GB\n",
      "1.9.0+cu111\n",
      "0.9.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import json\n",
    "import tgt\n",
    "import numpy as np\n",
    "import pyworld as pw\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm\n",
    "\n",
    "from scipy.io.wavfile import read\n",
    "import librosa\n",
    "from librosa.filters import mel as librosa_mel_fn\n",
    "import torch\n",
    "import torchaudio\n",
    "import glob\n",
    "# 환경 변수 설정\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '7'\n",
    "print(\"CUDA_VISIBLE_DEVICES:\", os.environ['CUDA_VISIBLE_DEVICES'])\n",
    "\n",
    "# CUDA 사용 가능 여부와 디바이스 수 확인\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "print(f\"Device Count: {torch.cuda.device_count()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Current CUDA Device: {torch.cuda.current_device()}\")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "print(torch.__version__, torch.cuda.device_count(), torch.cuda.get_device_name(0))\n",
    "\n",
    "MAX_WAV_VALUE = 32768.0\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchaudio.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TextGrid를 연다 \n",
    "# sentence interval을 가져온다 \n",
    "# xmin/xmax를 가져온다 \n",
    "# frame_rate에 따라 start_frame, end_frame을 구한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# textGridPath = glob.glob('/workspace/DATA/chem/sentences/*.TextGrid')\n",
    "root_path = '/workspace/DATA'\n",
    "speaker_name = 'chem'\n",
    "root_path = os.path.join(root_path, speaker_name)\n",
    "textGridPath = glob.glob(os.path.join(root_path,'sentences/*.TextGrid'))\n",
    "base_name = 'Sh42Wpvs42k'\n",
    "lip_embed = np.load(os.path.join(root_path,f'processed/mouth_emb/chem-face-{base_name}_face.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textGridPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lip_embedding을 열어본다. \n",
    "lip_embedding = np.load('/workspace/DATA/chem/processed/mouth_emb/chem-face-_56-KofIBng_face.npz')\n",
    "#/workspace/DATA/chem/preprocessed_test/duration/chem-_56-KofIBng-sentence-0.9-duration.npy\n",
    "# lip_lens = np.array([lip_e.shape[1] for lip_e in lip_embedding['data']])\n",
    "# lip_embedding = [lip_e[0] for lip_e in lip_embedding['data']]\n",
    "# frame수와 일치하는지 본다. \n",
    "# 일치하면 frame 수대로 자르면 되는데 \n",
    "# 이미지 리스트는 /workspace/DATA/chem/mouth 여기 있다.\n",
    "folder_path_list = glob.glob('/workspace/DATA/chem/mouth/*_face')\n",
    "folder = '/workspace/DATA/chem/mouth/_56-KofIBng_face'\n",
    "image_list = glob.glob(folder + '/*.jpg')\n",
    "tg_path = '/workspace/DATA/chem/sentences/_56-KofIBng.TextGrid'\n",
    "# 이미지 파일 리스트를 가져옵니다.\n",
    "folder = '/workspace/DATA/chem/mouth/_56-KofIBng_face'\n",
    "image_list = glob.glob(os.path.join(folder, '*.jpg'))\n",
    "base_name_list = [int(os.path.basename(name).split('.')[0]) for name in image_list]\n",
    "textgrid = tgt.io.read_textgrid(tg_path)\n",
    "sentences_tier = textgrid.get_tier_by_name(\"sentences\")\n",
    "frame_late = 25\n",
    "for sentence in sentences_tier._objects:\n",
    "    start_time = sentence.start_time\n",
    "    end_time = sentence.end_time\n",
    "    # 시작 프레임과 끝 프레임의 인덱스를 찾습니다.\n",
    "    start_frame_idx = np.searchsorted(base_name_list, int(start_time * 25), side='left')\n",
    "    end_frame_idx = np.searchsorted(base_name_list, int(end_time * 25), side='right')\n",
    "\n",
    "    # 해당 문장의 lip embedding을 추출합니다.\n",
    "    sentence_lip_embedding = lip_embedding['data'][0][start_frame_idx:end_frame_idx]\n",
    "\n",
    "# 추출한 lip embedding을 저장합니다.\n",
    "    output_path = f\"/workspace/DATA/chem/test_2/{'_56-KofIBng_text'}-sentence-{start_time}-mouth_emb.npy\"\n",
    "    np.save(output_path, sentence_lip_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame num : 4374  , lip_embedding_num: (1, 4374, 512)\n"
     ]
    }
   ],
   "source": [
    "# lip_embedding을 열어본다. \n",
    "lip_embedding = np.load('/workspace/DATA/chem/processed/mouth_emb/chem-face-_7s29Q76st0_face.npz')\n",
    "#mouth frame수와 일치하는지 본다. \n",
    "folder = '/workspace/DATA/chem/mouth/_7s29Q76st0_face'\n",
    "image_list = glob.glob(folder + '/*.jpg')\n",
    "base_name_List = [int(os.path.basename(name).split('.')[0]) for name in image_list]\n",
    "print(f\"frame num : {len(base_name_List)}  , lip_embedding_num: {lip_embedding['data'].shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 512)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lip_embedding['data'][0][0:3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 512)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lip_embedding['data'][0][0:4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HPM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
